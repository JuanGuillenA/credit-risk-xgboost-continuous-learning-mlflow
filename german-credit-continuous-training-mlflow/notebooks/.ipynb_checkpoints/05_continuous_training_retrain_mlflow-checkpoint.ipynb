{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aae8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base50 rows: 50\n",
      "Feedback rows: 0\n",
      "Train total rows: 50\n",
      "✅ New version: v_20260202_005937\n",
      "✅ Metrics: {'accuracy': 0.652, 'f1': 0.7728459530026109, 'precision': 0.7115384615384616, 'recall': 0.8457142857142858, 'roc_auc': 0.6361904761904762}\n",
      "✅ Updated registry: ../artifacts/models/model_registry.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanguillenalbarracin/anaconda3/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import os, json, time\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"CooperativeCreditRisk-XGBoost\")\n",
    "\n",
    "os.makedirs(\"../artifacts/models\", exist_ok=True)\n",
    "os.makedirs(\"../artifacts/reports\", exist_ok=True)\n",
    "\n",
    "FEATURES = [\n",
    "    \"duration\",\"credit_amount\",\"age\",\n",
    "    \"checking_status\",\"employment\",\"savings_status\",\"purpose\"\n",
    "]\n",
    "TARGET = \"target\"\n",
    "\n",
    "fixed_test_path   = \"../artifacts/dataset/fixed_test.csv\"\n",
    "base50_path       = \"../artifacts/dataset/initial_base_50.csv\"\n",
    "future_pool_path  = \"../artifacts/dataset/future_pool.csv\"\n",
    "feedback_path     = \"../artifacts/dataset/feedback_new_data.csv\"  # igual que app\n",
    "registry_path     = \"../artifacts/models/model_registry.json\"\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "def log(msg):\n",
    "    ts = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\", flush=True)\n",
    "\n",
    "def ensure_cols(df, cols, name):\n",
    "    miss = [c for c in cols if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"{name}: faltan columnas {miss}\")\n",
    "\n",
    "def evaluate(model, X_eval, y_eval):\n",
    "    proba = model.predict_proba(X_eval)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y_eval, pred)),\n",
    "        \"f1\": float(f1_score(y_eval, pred)),\n",
    "        \"precision\": float(precision_score(y_eval, pred)),\n",
    "        \"recall\": float(recall_score(y_eval, pred)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_eval, proba)),\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Load fixed test\n",
    "# =========================\n",
    "if not os.path.exists(fixed_test_path):\n",
    "    raise FileNotFoundError(f\"fixed_test no encontrado: {fixed_test_path}\")\n",
    "\n",
    "fixed_test = pd.read_csv(fixed_test_path)\n",
    "ensure_cols(fixed_test, FEATURES + [TARGET], \"fixed_test\")\n",
    "fixed_test[TARGET] = fixed_test[TARGET].astype(int)\n",
    "\n",
    "X_test = fixed_test[FEATURES].copy()\n",
    "y_test = fixed_test[TARGET].copy()\n",
    "\n",
    "# =========================\n",
    "# Load base50\n",
    "# =========================\n",
    "base50 = pd.read_csv(base50_path)\n",
    "ensure_cols(base50, FEATURES + [TARGET], \"base50\")\n",
    "base50[TARGET] = base50[TARGET].astype(int)\n",
    "\n",
    "# =========================\n",
    "# Load future_pool + take batch\n",
    "# =========================\n",
    "future_pool = pd.read_csv(future_pool_path)\n",
    "ensure_cols(future_pool, FEATURES + [TARGET], \"future_pool\")\n",
    "future_pool[TARGET] = future_pool[TARGET].astype(int)\n",
    "\n",
    "take_n = min(batch_size, len(future_pool))\n",
    "if take_n == 0:\n",
    "    batch = future_pool.copy()\n",
    "    future_remaining = future_pool.copy()\n",
    "else:\n",
    "    batch = future_pool.sample(take_n, random_state=7)\n",
    "    future_remaining = future_pool.drop(batch.index)\n",
    "\n",
    "# persist remaining\n",
    "future_remaining.to_csv(future_pool_path, index=False)\n",
    "\n",
    "# =========================\n",
    "# Load feedback (from app)\n",
    "# =========================\n",
    "if os.path.exists(feedback_path):\n",
    "    feedback = pd.read_csv(feedback_path)\n",
    "    ensure_cols(feedback, FEATURES + [TARGET], \"feedback\")\n",
    "    feedback[TARGET] = feedback[TARGET].astype(int)\n",
    "else:\n",
    "    feedback = pd.DataFrame(columns=FEATURES + [TARGET])\n",
    "\n",
    "log(f\"Base50 rows: {len(base50)}\")\n",
    "log(f\"Future pool before: {len(future_pool)}\")\n",
    "log(f\"Batch taken: {len(batch)}\")\n",
    "log(f\"Future pool after: {len(future_remaining)}\")\n",
    "log(f\"Feedback rows: {len(feedback)}\")\n",
    "\n",
    "# =========================\n",
    "# Train set: base50 + batch + feedback\n",
    "# =========================\n",
    "train_plus = pd.concat([base50, batch, feedback], ignore_index=True)\n",
    "ensure_cols(train_plus, FEATURES + [TARGET], \"train_plus\")\n",
    "\n",
    "X_train = train_plus[FEATURES].copy()\n",
    "y_train = train_plus[TARGET].astype(int).copy()\n",
    "\n",
    "log(f\"Train total rows: {len(train_plus)}\")\n",
    "log(f\"Fixed test rows: {len(X_test)}\")\n",
    "\n",
    "# =========================\n",
    "# Pipeline\n",
    "# =========================\n",
    "cat_cols = [\"checking_status\",\"employment\",\"savings_status\",\"purpose\"]\n",
    "num_cols = [\"duration\",\"credit_amount\",\"age\"]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=450,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.90,\n",
    "    colsample_bytree=0.90,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"logloss\",\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", xgb)])\n",
    "\n",
    "# version name\n",
    "version = \"v_\" + datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# =========================\n",
    "# Train with visible progress\n",
    "# =========================\n",
    "with mlflow.start_run(run_name=f\"retrain_{version}\") as run:\n",
    "    t0 = time.time()\n",
    "\n",
    "    log(\"Training start (with XGBoost verbose eval)...\")\n",
    "\n",
    "    # transform first to pass eval_set to XGBClassifier\n",
    "    pre = pipe.named_steps[\"preprocess\"]\n",
    "    model = pipe.named_steps[\"model\"]\n",
    "\n",
    "    Xtr = pre.fit_transform(X_train)\n",
    "    Xev = pre.transform(X_test)\n",
    "\n",
    "    model.fit(\n",
    "        Xtr, y_train,\n",
    "        eval_set=[(Xev, y_test)],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    log(f\"Training finished in {time.time() - t0:.2f}s\")\n",
    "\n",
    "    metrics = evaluate(pipe, X_test, y_test)\n",
    "\n",
    "    mlflow.log_param(\"deployment_version\", version)\n",
    "    mlflow.log_param(\"batch_size_used\", int(len(batch)))\n",
    "    mlflow.log_param(\"future_pool_remaining\", int(len(future_remaining)))\n",
    "    mlflow.log_param(\"base_rows\", int(len(base50)))\n",
    "    mlflow.log_param(\"feedback_rows\", int(len(feedback)))\n",
    "    mlflow.log_param(\"train_total_rows\", int(len(train_plus)))\n",
    "    mlflow.log_param(\"test_rows_fixed\", int(len(X_test)))\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        mlflow.log_metric(k, v)\n",
    "\n",
    "    model_path = f\"../artifacts/models/model_{version}.joblib\"\n",
    "    joblib.dump(pipe, model_path)\n",
    "\n",
    "    metrics_path = f\"../artifacts/reports/metrics_{version}.json\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model_joblib\")\n",
    "    mlflow.log_artifact(metrics_path, artifact_path=\"reports\")\n",
    "    mlflow.sklearn.log_model(\n",
    "    pipe,\n",
    "    artifact_path=\"sklearn_model\",\n",
    "    registered_model_name=\"CooperativeCreditRisk-XGBoost\"\n",
    ")\n",
    "\n",
    "\n",
    "log(\"New version: \" + version)\n",
    "log(\"Metrics: \" + str(metrics))\n",
    "\n",
    "# =========================\n",
    "# Update registry\n",
    "# =========================\n",
    "with open(registry_path, \"r\") as f:\n",
    "    registry = json.load(f)\n",
    "\n",
    "registry[\"current_version\"] = version\n",
    "registry[\"models\"][version] = {\n",
    "    \"path\": f\"artifacts/models/model_{version}.joblib\",\n",
    "    \"metrics_path\": f\"artifacts/reports/metrics_{version}.json\"\n",
    "}\n",
    "\n",
    "with open(registry_path, \"w\") as f:\n",
    "    json.dump(registry, f, indent=2)\n",
    "\n",
    "log(\"Updated registry: \" + registry_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9680d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
